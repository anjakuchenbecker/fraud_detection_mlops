/*
Purpose: 
- Runs the latest version of automated continuous training (CT) pipeline
Trigger(s): 
- On schedule (once a month)
- When data drift has been detected by prometheus monitoring
- When new continuous training (CT) pipeline has been deployed to local docker registry
Interacts with: 
- Local docker registry
- ?Feature Store / Data Sources
- MLflow Tracking Server (and indirectly with MLflow Artifact Server)
*/
import groovy.json.JsonSlurper 

pipeline {
    agent any
    environment {
        LOCAL_DOCKER_REPO = "fraud_detection_ct_pipeline"
        LOCAL_DOCKER_REGISTRY = "localhost:5000"
        LOCAL_DOCKER_IMAGE_TAGS_URL = "http://docker_registry:5000/v2/${LOCAL_DOCKER_REPO}/tags/list"
        MLFLOW_TRACKING_SERVER_URL = "http://mlflow_tracking_server:5555"
        MLFLOW_EXPERIMENT_NAME = "fraud_detection_production"
        DOCKER_NETWORK = "iubh_dlbdsmtp01_t3_fraud_detection_mlops_default"
    }
    /*
    triggers {
        cron("TBD")
    }
    */
    stages {
        stage("Setup CT Pipeline") {
            /*
            Determines latest image version of CT pipeline. Pulls images from local docker registry and runs it.
            */
            steps {
                // determine latest image version
                script {
                    def response = httpRequest "${LOCAL_DOCKER_IMAGE_TAGS_URL}"
                    def json = new JsonSlurper().parseText(response.content)
                    env.LATEST_CT_PIPELINE_TAG = json.tags.max()
                    env.IMAGE_NAME = "${LOCAL_DOCKER_REGISTRY}/${LOCAL_DOCKER_REPO}:${LATEST_CT_PIPELINE_TAG}".trim()
                    env.CONTAINER_NAME = "${LOCAL_DOCKER_REPO}_${LATEST_CT_PIPELINE_TAG}"
                }
                // pull image
                sh "docker pull ${IMAGE_NAME}"
                // run container based on image (interactive, detached and connected to given network)
                sh "docker run -it -d -e MLFLOW_TRACKING_SERVER_URL=${MLFLOW_TRACKING_SERVER_URL} -e MLFLOW_EXPERIMENT_NAME=${MLFLOW_EXPERIMENT_NAME} --network ${DOCKER_NETWORK} --name ${CONTAINER_NAME} ${IMAGE_NAME}"
            }
        }
        stage("Ingest Data") {
            /*
            Reads data from data source and splits the data into different datasets (all, train and test).
            Input: Raw data
            Output: raw_data.<file> (all), raw_train.<file>, raw_test.<file>
            */
            steps {
                sh "docker exec ${CONTAINER_NAME} python3 opt/custom/ingest.py"
            }
        }
        stage("Validate Data") {
            /*
            Checks the quality of the new data and if our expectations are met.
            Input: raw_train.<file>, raw_test.<file>, raw data expectations
            Output: Validation result (result_OK:go to next stage or result_NOK:stop pipeline)
            */
            steps {
                sh "docker exec ${CONTAINER_NAME} python3 opt/custom/validate_data.py"
            }
        }
        stage("Preprocess Data") {
            /*
            TBD
            Input: raw_train.<file>, raw_test.<file>, processed data expectations
            Output: processed_train.<file>, processed_test.<file>
            */
            steps {
                sh "docker exec ${CONTAINER_NAME} python3 opt/custom/preprocess.py"
            }
        }
        stage("Train Model") {
            /*
            Re-trains model on training dataset, calculates evaluation metrics on test dataset.
            Reports training to MLflow Tracking Server.
            Input: processed_train.<file>, processed_test.<file>
            Output: trained model, evaluation metrics, new experiment run on MLflow Tracking Server
            */
            steps {
                script {
                    env.MLFLOW_RUN_ID = sh ( 
                        script: "docker exec ${CONTAINER_NAME} python3 opt/custom/train.py",
                        returnStdout: true
                    ).trim()
                }
            }
        }
        stage("Evaluate Model") {
            /*
            Checks the performance of trained model against our expectations.
            Input: Evaluation metrics, metric expectations
            Output: Validation result (result_OK:go to next stage or result_NOK:stop pipeline), TBD
            */
            steps {
                sh "docker exec ${CONTAINER_NAME} python3 opt/custom/evaluate.py ${MLFLOW_RUN_ID}"
            }
        }
        stage("Validate Model") {
            /*
            Deploys and tests the model in staging environment.
            Input: trained model, staging environment
            Output: Validation result (result_OK:go to next stage or result_NOK:stop pipeline), TBD
            */
            steps {
                sh "docker exec ${CONTAINER_NAME} python3 opt/custom/validate_model.py"
            }
        }
        stage("Deploy Model") {
            /*
            Deploys the model in production environment.
            Input: trained model, production environment
            Output: Re-trained model in production environment
            */
            steps {
                sh "docker exec ${CONTAINER_NAME} python3 opt/custom/deploy.py"
            }
        }
        stage("Shutdown CT Pipeline") {
            /*
            */
            steps {
                // remove CT pipeline (force removal during running inclusive volumnes)
                sh "docker rm -fv ${CONTAINER_NAME}"
                // remove locally-cached image
                sh "docker image rm ${IMAGE_NAME}"
            }
        }
    }
}